{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a8aff49-1df5-4228-bf50-bc10a65800b1",
   "metadata": {},
   "source": [
    "### @Author: Yousef Alkhanafseh\n",
    "### @E-mail: alkhanafseh15@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71498e29-1cc7-4314-bac6-43677f829554",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211e6d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-03 17:14:43.124280: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-03 17:14:43.853437: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759500884.045353   20378 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759500884.102574   20378 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-03 17:14:44.552829: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import tensorflow as tf\n",
    "import tf_keras\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317779b-c2f6-4b87-a505-5c6d08f2f30e",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9820cf62-db5e-48c8-b095-fdf03263c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_DIR = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd()\n",
    "\n",
    "# Option A: simple, script-relative\n",
    "image_dir = SCRIPT_DIR / \"data\" / \"images\" / \"images\"\n",
    "image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb935d9-0df7-4f5f-bb43-723478cc6244",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_path = \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\"\n",
    "image_dir = os.path.join(os.getcwd(), \"data\", \"images\", \"images\")\n",
    "\n",
    "image_shape = (224, 224)\n",
    "\n",
    "mainclass_dict = {\n",
    "                    'A1':0, 'A2':1, 'A3':2,\n",
    "                    'A4':3, 'A5':4, 'A6':5\n",
    "                 }\n",
    "\n",
    "subclass_dict = { \n",
    "                    'off_off_on_on':0, 'off_on_off_on':1, 'off_on_on_off':2,\n",
    "                    'off_on_on_on':3, 'on_off_off_on':4, 'on_off_on_off':5,\n",
    "                    'on_off_on_on':6, 'on_on_off_off':7, 'on_on_off_on':8,\n",
    "                    'on_on_on_off':9, 'off_off_off_off':10, 'on_on_on_on':11\n",
    "                }\n",
    "\n",
    "bins = {\n",
    "        0:  (0,  0.3),   \n",
    "        1:  (0.3,  3.0),  \n",
    "        2:  (3.0,  5.6),  \n",
    "        3:  (5.6,  8.2),  \n",
    "        4:  (8.2, 13.0),   \n",
    "        5:  (13.0, 17.0),  \n",
    "        6:  (17.0, 20.5),  \n",
    "        7:  (20.5, 24.5),   \n",
    "        8:  (24.5, 46.2),   \n",
    "        9:  (46.2, 68.2),  \n",
    "        10:  (68.2, 90.2),   \n",
    "        11: (90.2, 107.9), \n",
    "        12: (107.9, 110.0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67e7d20",
   "metadata": {},
   "source": [
    "# Image data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51f8a86-1008-4e51-b6b3-b72bd615e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_img_data(X_mainLst, y_mainLst, y_subLst, y_distlst):\n",
    "\n",
    "    print(\"Image reading process is started !!\")\n",
    "\n",
    "    X_out_mainLst = []\n",
    "    y_out_mainLst = []\n",
    "    y_out_subLst = []\n",
    "    y_out_distlst = []\n",
    "    X_path_lst = []\n",
    "    error_lst = []\n",
    "    \n",
    "    for img_path, ymain, ysub, ydist in zip(X_mainLst, y_mainLst, y_subLst, y_distlst):\n",
    "        try:\n",
    "            one_image = cv2.imread(str(img_path))\n",
    "            if one_image is None:\n",
    "                print(f\"Could not read image file: {img_path}\")\n",
    "                error_lst.append(img_path)\n",
    "            one_image = cv2.cvtColor(one_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            one_image = cv2.resize(one_image, image_shape)\n",
    "            \n",
    "            X_out_mainLst.append(one_image)\n",
    "            X_path_lst.append(img_path)\n",
    "            y_out_mainLst.append(ymain)\n",
    "            y_out_subLst.append(ysub)\n",
    "            y_out_distlst.append(ydist)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(img_path, e)\n",
    "\n",
    "    return error_lst, X_path_lst, np.array(X_out_mainLst), np.array(y_out_mainLst), np.array(y_out_subLst), np.array(y_out_distlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e27a6-fffd-4dfa-a5d7-88844c73e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_path_finder(image_dir, fprefix):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(image_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(fprefix):\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc4207-a9bf-4e99-a047-1c03cf47e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_img_paths = file_path_finder(image_dir, '.png')\n",
    "\n",
    "y_main = []\n",
    "y_sub = []\n",
    "y_dist = []  \n",
    "\n",
    "for imgpath in file_img_paths:\n",
    "    main_key = imgpath.rsplit(\"/\", 2)[-2]\n",
    "    filename = imgpath.rsplit(\"/\", 1)[-1].replace(\".png\", \"\")\n",
    "    first_underscore_split = filename.split(\"_\", 1)\n",
    "    distance_str = first_underscore_split[0]\n",
    "    distance_val = str(distance_str)\n",
    "    remainder = first_underscore_split[1]\n",
    "    sub_key    = remainder.replace(\"_plot\", \"\")\n",
    "\n",
    "\n",
    "    y_main.append(mainclass_dict[main_key])\n",
    "    y_sub.append(subclass_dict[sub_key])\n",
    "\n",
    "    if sub_key == \"off_off_off_off\":\n",
    "        y_dist.append(0)\n",
    "    else:\n",
    "        y_dist.append(distance_val)\n",
    "        \n",
    "y_main = np.array(y_main)\n",
    "y_sub  = np.array(y_sub)\n",
    "y_dist = np.array(y_dist)\n",
    "\n",
    "\n",
    "X_train_val, X_test_temp, \\\n",
    "y_main_train_val, y_main_test, \\\n",
    "y_sub_train_val,  y_sub_test, \\\n",
    "y_dist_train_val, y_dist_test = train_test_split(\n",
    "    file_img_paths,     \n",
    "    y_main, y_sub, y_dist,    \n",
    "    test_size=0.15,      # 15 % held out for final testing\n",
    "    random_state=42,\n",
    "    stratify=y_dist      # <-- preserves distance-bin distribution\n",
    ")\n",
    "\n",
    "# ── 2) train + val ───────────────────\n",
    "X_train_temp, X_val_temp, \\\n",
    "y_main_train, y_main_val, \\\n",
    "y_sub_train,  y_sub_val, \\\n",
    "y_dist_train, y_dist_val = train_test_split(\n",
    "    X_train_val,\n",
    "    y_main_train_val, y_sub_train_val, y_dist_train_val,\n",
    "    test_size=0.1765,     # 0.1765 × 0.85 ≈ 0.15  → overall 15 % validation\n",
    "    random_state=42,\n",
    "    stratify=y_dist_train_val   # <-- keep the same balance here too\n",
    ")\n",
    "\n",
    "print(len(y_main_train), len(y_main_val), len(y_main_test))\n",
    "print(len(y_sub_train),  len(y_sub_val),  len(y_sub_test))\n",
    "print(len(y_dist_train), len(y_dist_val), len(y_dist_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add06c75-5fad-4662-be7a-a7f44112ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train_lst, X_train_temp, X_train_img, y_main_train, y_sub_train, y_dist_train = return_img_data(X_train_temp, y_main_train, y_sub_train, y_dist_train)\n",
    "error_val_lst, X_val_temp, X_val_img, y_main_val, y_sub_val, y_dist_val = return_img_data(X_val_temp, y_main_val, y_sub_val, y_dist_val)\n",
    "error_test_lst, X_test_temp, X_test_img, y_main_test, y_sub_test, y_dist_test = return_img_data(X_test_temp, y_main_test, y_sub_test, y_dist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022971e2-fd77-4ddc-9c84-dee55f007f50",
   "metadata": {},
   "source": [
    "# Fault distance bins balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d85d2b-2b17-478a-b4e0-939822da97e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_bins(datalist):\n",
    "    new_list = []\n",
    "    for i in datalist.tolist():\n",
    "        for binindex, binrange in bins.items():\n",
    "            if  float(binrange[0]) <= float(i) < float(binrange[1]):\n",
    "                new_list.append(binindex)\n",
    "    return np.array(new_list)\n",
    "\n",
    "def assign_bin(x):\n",
    "    for idx, (lo, hi) in bins.items():\n",
    "        if lo <= float(x) <= hi:\n",
    "            return idx\n",
    "\n",
    "def assign_binrange(x):\n",
    "    for idx, (lo, hi) in bins.items():\n",
    "        if lo <= float(x) <= hi:\n",
    "            return str(lo) + \" - \" + str(hi) + \" km\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb86c39-e74f-4b4c-b9c7-fb7583342a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dist_train_f = balanced_bins(y_dist_train)\n",
    "y_dist_val_f = balanced_bins(y_dist_val)\n",
    "y_dist_test_f = balanced_bins(y_dist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f13d3d-2b45-46b6-9b6b-8ce27b785063",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_temp_df = pd.DataFrame(y_dist_train.tolist())\n",
    "bins_temp_df = bins_temp_df.rename({0:\"distance\"}, axis=1)\n",
    "bins_temp_df[\"bin\"] = bins_temp_df[\"distance\"].apply(assign_bin)\n",
    "bins_temp_df[\"distance_range\"] = bins_temp_df[\"distance\"].apply(assign_binrange)\n",
    "bins_temp_df = bins_temp_df.groupby([\"distance_range\", \"bin\"], as_index=False).count()\n",
    "temp_dist_df = bins_temp_df.rename({\"distance\":\"count\", \"bin\":\"class_id\"}, axis=1)\n",
    "\n",
    "temp_dist_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744aaa6b-fff2-4c8b-a15d-cca031245238",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936dd7c9-10f4-4709-8b66-156cc36ab13d",
   "metadata": {},
   "source": [
    "## GLA layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1261180-72a5-46e2-8b8c-0aa563e97246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLALayer(tf_keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Gated Linear Attention (single head, O(N·d) time, O(d) memory)\n",
    "    • inputs  : (batch, seq_len, dim)\n",
    "    • outputs : (batch, seq_len, dim)    -- same shape\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        # linear projections for q, k, v, and the gate\n",
    "        self.to_q = tf_keras.layers.Dense(dim, use_bias=False)\n",
    "        self.to_k = tf_keras.layers.Dense(dim, use_bias=False)\n",
    "        self.to_v = tf_keras.layers.Dense(dim, use_bias=False)\n",
    "        self.to_gate = tf_keras.layers.Dense(dim, use_bias=True)\n",
    "\n",
    "    # ϕ(x) = ELU(x) + 1  (as in the paper)\n",
    "    @staticmethod\n",
    "    def phi(x):  \n",
    "        return tf.nn.elu(x) + 1.0\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        q = self.phi(self.to_q(inputs))          # (B,S,D)\n",
    "        k = self.phi(self.to_k(inputs))          # (B,S,D)\n",
    "        v =            self.to_v(inputs)         # (B,S,D)\n",
    "\n",
    "        # -------- linear attention core ------------\n",
    "        kv = tf.einsum('bsd,bsf->bdf', k, v)      # (B,D,D)\n",
    "        z  = 1.0 / (tf.einsum('bsd,bd->bs', q,\n",
    "                              tf.reduce_sum(k, axis=1)) + 1e-6)   # (B,S)\n",
    "        y  = tf.einsum('bsd,bdf->bsf', q, kv)     # (B,S,D)\n",
    "        y  = y * tf.expand_dims(z, -1)            # (B,S,D)\n",
    "\n",
    "        # -------- gating ---------------------------\n",
    "        gate = tf.sigmoid(self.to_gate(inputs))   # (B,S,D)\n",
    "        return gate * y\n",
    "\n",
    "# Custom sharpening layer\n",
    "class SharpenLayer(tf_keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SharpenLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define a 3x3 sharpening kernel\n",
    "        kernel = tf.constant([[0, -1, 0],\n",
    "                              [-1, 5, -1],\n",
    "                              [0, -1, 0]], dtype=tf.float32)\n",
    "        kernel = tf.reshape(kernel, [3, 3, 1, 1])\n",
    "        in_channels = tf.shape(inputs)[-1]\n",
    "        kernel = tf.tile(kernel, [1, 1, in_channels, 1])\n",
    "        return tf.nn.depthwise_conv2d(inputs, kernel, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e0ae33-6c7e-4384-bcef-753efe72363e",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc4f4b7-a4e1-491f-8c62-79869c5e3c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom sharpening layer\n",
    "class SharpenLayer(tf_keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SharpenLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define a 3x3 sharpening kernel\n",
    "        kernel = tf.constant([[0, -1, 0],\n",
    "                              [-1, 5, -1],\n",
    "                              [0, -1, 0]], dtype=tf.float32)\n",
    "        kernel = tf.reshape(kernel, [3, 3, 1, 1])\n",
    "        in_channels = tf.shape(inputs)[-1]\n",
    "        kernel = tf.tile(kernel, [1, 1, in_channels, 1])\n",
    "        return tf.nn.depthwise_conv2d(inputs, kernel, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c164480-23a9-4538-9e60-19f29bb3f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mhwmg_model(n_main=6, n_sub=12, n_dist=12):\n",
    "    \"\"\"\n",
    "    Inference-only MH-WMG model builder.\n",
    "    Same architecture as your training graph, but without compile/optimizer/callbacks.\n",
    "    \"\"\"\n",
    "\n",
    "    data_augmentation = tf_keras.Sequential(\n",
    "        [\n",
    "            tf_keras.layers.RandomContrast(0.3, input_shape=image_shape + (3,)),\n",
    "            tf_keras.layers.Lambda(lambda x: tf.image.adjust_brightness(x, delta=0.1)),\n",
    "            SharpenLayer(),\n",
    "        ],\n",
    "        name=\"data_augmentation\",\n",
    "    )\n",
    "\n",
    "    inputs = tf_keras.Input(shape=image_shape + (3,), name=\"input_image\")\n",
    "    augmented = data_augmentation(inputs)\n",
    "\n",
    "    features = hub.KerasLayer(\n",
    "        fm_path,\n",
    "        input_shape=image_shape + (3,),\n",
    "        trainable=True,\n",
    "        name=\"mobilenetv3_small_features\",\n",
    "    )(augmented)\n",
    "\n",
    "    print(features.shape)\n",
    "\n",
    "    x1 = tf_keras.layers.Dropout(0.3, name=\"dropout_x1\")(features)\n",
    "    x1 = tf_keras.layers.Dense(\n",
    "        2 ** 8, activation=\"relu\",\n",
    "        kernel_regularizer=tf_keras.regularizers.L2(0.2),\n",
    "        name=\"dense_x1\",\n",
    "    )(x1)\n",
    "\n",
    "    x2 = tf_keras.layers.Dropout(0.3, name=\"dropout_x2\")(x1)\n",
    "\n",
    "    xx = tf_keras.layers.Dense(\n",
    "        2 ** 9, activation=\"relu\",\n",
    "        kernel_regularizer=tf_keras.regularizers.L1(0.1),\n",
    "        name=\"dense_xx\",\n",
    "    )(features)\n",
    "    xx = tf_keras.layers.Dropout(0.5, name=\"dropout_xx\")(xx)\n",
    "\n",
    "    tokens = tf_keras.layers.Reshape((32, 16), name=\"tokens_reshape\")(xx)\n",
    "    tokens = GLALayer(dim=16, name=\"gla\")(tokens)\n",
    "\n",
    "    x3 = tf_keras.layers.Flatten(name=\"flatten_tokens\")(tokens)\n",
    "    x3 = tf_keras.layers.BatchNormalization(name=\"bn_x3\")(x3)\n",
    "    x3 = tf_keras.layers.Dropout(0.6, name=\"dropout_x3\")(x3)\n",
    "\n",
    "    main_output = tf_keras.layers.Dense(\n",
    "        n_main, activation=\"softmax\",\n",
    "        kernel_regularizer=tf_keras.regularizers.L2(0.1),\n",
    "        name=\"falut_area_output\",\n",
    "    )(x1)\n",
    "\n",
    "    subclass_output = tf_keras.layers.Dense(\n",
    "        n_sub, activation=\"softmax\",\n",
    "        kernel_regularizer=tf_keras.regularizers.L2(0.2),\n",
    "        name=\"falut_type_output\",\n",
    "    )(x2)\n",
    "\n",
    "    dist_output = tf_keras.layers.Dense(\n",
    "        n_dist, activation=\"softmax\",\n",
    "        kernel_regularizer=tf_keras.regularizers.L1(0.1),\n",
    "        name=\"falut_distance_bin_output\",\n",
    "    )(x3)\n",
    "\n",
    "    return tf_keras.Model(\n",
    "        inputs=inputs,\n",
    "        outputs=[main_output, subclass_output, dist_output],\n",
    "        name=\"mhwmg\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b079c5a-f6c5-4675-9a69-cbd697d515c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"ckpts\", exist_ok=True)\n",
    "\n",
    "ckpt = tf_keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"ckpts/mhwmg_{epoch:03d}_{val_falut_distance_bin_output_accuracy:.3f}.weights.h5\",\n",
    "    monitor=\"val_falut_distance_bin_output_accuracy\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"max\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 2**4\n",
    "base_learning_rate = 0.000045\n",
    "EPOCH = 100\n",
    "\n",
    "model = mhwmg_model()\n",
    "model.compile(\n",
    "    optimizer= tf_keras.optimizers.Adam(base_learning_rate),\n",
    "    loss={\n",
    "        'falut_area_output': 'sparse_categorical_crossentropy',\n",
    "        'falut_type_output': 'sparse_categorical_crossentropy',\n",
    "        'falut_distance_bin_output': 'sparse_categorical_crossentropy'\n",
    "    },\n",
    "\n",
    "    loss_weights={\n",
    "       'falut_area_output': 1.0,\n",
    "       'falut_type_output': 3.0,\n",
    "       'falut_distance_bin_output': 6.0\n",
    "    },\n",
    "    metrics={\n",
    "        'falut_area_output': 'accuracy',\n",
    "        'falut_type_output': 'accuracy',\n",
    "        'falut_distance_bin_output': 'accuracy'\n",
    "    }\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train_img,\n",
    "    y={\n",
    "       'falut_area_output': y_main_train,\n",
    "       'falut_type_output': y_sub_train,\n",
    "       'falut_distance_bin_output': np.array(y_dist_train_f)\n",
    "    },\n",
    "    validation_data=(\n",
    "        X_val_img,\n",
    "        {\n",
    "            'falut_area_output': y_main_val,\n",
    "            'falut_type_output': y_sub_val,\n",
    "            'falut_distance_bin_output': np.array(y_dist_val_f)\n",
    "        }\n",
    "    ),\n",
    "    epochs=EPOCH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[ckpt])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006164b9-8875-4229-b51b-cb76d0c18d46",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dcb3d7-cdc2-48ea-a130-4c9211cffb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_main, pred_sub, pred_dist = model.predict(X_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac23df-2acc-4bd4-b116-45f5f2705a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def head_metrics(y_true, y_pred_probs):\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.asarray(y_true)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "results = []\n",
    "for head_name, y_true, y_pred_probs in [\n",
    "    (\"fault_area\", y_main_test, pred_main),\n",
    "    (\"fault_type\", y_sub_test, pred_sub),\n",
    "    (\"fault_distance_bin\", np.array(y_dist_test_f), pred_dist),\n",
    "]:\n",
    "    acc, prec, rec, f1 = head_metrics(y_true, y_pred_probs)\n",
    "    results.append(\n",
    "        {\"head\": head_name,\n",
    "         \"accuracy\": acc,\n",
    "         \"precision_macro\": prec,\n",
    "         \"recall_macro\": rec,\n",
    "         \"f1_macro\": f1}\n",
    "    )\n",
    "\n",
    "metrics_df = pd.DataFrame(results)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe87701-af14-4e2b-8492-c89aae5b4349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_elk",
   "language": "python",
   "name": "tf_elk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
